=> loading model from ../output/egocentric_weipeng/egocentric_adadelta_epoch20_weipeng/checkpoint_epoch_1000.pth.tar
Traceback (most recent call last):
  File "run.py", line 132, in <module>
    main()
  File "run.py", line 84, in main
    pretrained_dict = torch.load(model_state_file)['state_dict']
  File "/home/jianwang/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 585, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/jianwang/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 765, in _legacy_load
    result = unpickler.load()
  File "/home/jianwang/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 721, in persistent_load
    deserialized_objects[root_key] = restore_location(obj, location)
  File "/home/jianwang/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 174, in default_restore_location
    result = fn(storage, location)
  File "/home/jianwang/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 150, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/jianwang/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 134, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
